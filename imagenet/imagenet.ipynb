{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1225989.77s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n",
      "<TITLE>301 Moved</TITLE></HEAD><BODY>\n",
      "<H1>301 Moved</H1>\n",
      "The document has moved\n",
      "<A HREF=\"http://www.google.com/\">here</A>.\n",
      "</BODY></HTML>\n"
     ]
    }
   ],
   "source": [
    "! curl google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import alexnet\n",
    "\"\"\"\n",
    "- Input image : 224 x 224 x 3\n",
    "- Kernels : 11x 11 x 3\n",
    "- Stride = 4\n",
    "- out_channel = 96\n",
    "\n",
    "\n",
    "- Input image : 224 x 224 x 3\n",
    "- Kernels : 5x 5x 3\n",
    "- Stride = 1\n",
    "- out_channel = 256\n",
    "\"\"\"\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self , classes) -> None:\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11 , stride=4), # b * 96 * 55 * 55\n",
    "        nn.LocalResponseNorm(size=5, k=2),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2), # b* 96 * 27 * 27\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5),\n",
    "        nn.LocalResponseNorm(size=5, k=2),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # N x 1024\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=(256 * 2* 2), out_features=4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=4096, out_features=4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=4096, out_features=classes),  # Adjusted for the number of classes\n",
    "        )\n",
    "        self.init_parameter()\n",
    "\n",
    "    def init_parameter(self):\n",
    "        for layer in self.convs:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.1),\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "            \n",
    "        nn.init.constant_(self.convs[4].bias, 1)\n",
    "        nn.init.constant_(self.convs[10].bias, 1)\n",
    "        nn.init.constant_(self.convs[12].bias, 1)\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = self.convs(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10 | Loss: 62.85303497314453\n",
      "step: 20 | Loss: 24.686874389648438\n",
      "step: 30 | Loss: 13.686965942382812\n",
      "step: 40 | Loss: 8.942755699157715\n",
      "step: 50 | Loss: 7.785600662231445\n",
      "step: 60 | Loss: 7.13751745223999\n",
      "step: 70 | Loss: 7.014235019683838\n",
      "step: 80 | Loss: 7.003018379211426\n",
      "step: 90 | Loss: 7.026607036590576\n",
      "step: 100 | Loss: 6.997574806213379\n",
      "step: 110 | Loss: 6.9550909996032715\n",
      "step: 120 | Loss: 6.96130895614624\n",
      "step: 130 | Loss: 6.9493021965026855\n",
      "step: 140 | Loss: 6.938838958740234\n",
      "step: 150 | Loss: 6.968613147735596\n",
      "step: 160 | Loss: 6.966643810272217\n",
      "step: 170 | Loss: 6.953219413757324\n",
      "step: 180 | Loss: 6.888947010040283\n",
      "step: 190 | Loss: 6.949268817901611\n",
      "step: 200 | Loss: 6.902809143066406\n",
      "step: 210 | Loss: 6.93674898147583\n",
      "step: 220 | Loss: 6.908194541931152\n",
      "step: 230 | Loss: 6.902073383331299\n",
      "step: 240 | Loss: 6.8833770751953125\n",
      "step: 250 | Loss: 6.879649639129639\n",
      "step: 260 | Loss: 6.92280387878418\n",
      "step: 270 | Loss: 6.9131388664245605\n",
      "step: 280 | Loss: 6.919199466705322\n",
      "step: 290 | Loss: 6.897252082824707\n",
      "step: 300 | Loss: 6.915024757385254\n",
      "step: 310 | Loss: 6.893312931060791\n",
      "step: 320 | Loss: 6.9176926612854\n",
      "step: 330 | Loss: 6.9051032066345215\n",
      "step: 340 | Loss: 6.9062910079956055\n",
      "step: 350 | Loss: 6.8781208992004395\n",
      "step: 360 | Loss: 6.910148620605469\n",
      "step: 370 | Loss: 6.886528968811035\n",
      "step: 380 | Loss: 6.904715538024902\n",
      "step: 390 | Loss: 6.887540340423584\n",
      "step: 400 | Loss: 6.905600070953369\n",
      "step: 410 | Loss: 6.9273905754089355\n",
      "step: 420 | Loss: 6.915843963623047\n",
      "step: 430 | Loss: 6.881242275238037\n",
      "step: 440 | Loss: 6.88290548324585\n",
      "step: 450 | Loss: 6.904751777648926\n",
      "step: 460 | Loss: 6.91149377822876\n",
      "step: 470 | Loss: 6.926733493804932\n",
      "step: 480 | Loss: 6.893121242523193\n",
      "step: 490 | Loss: 6.924897193908691\n",
      "step: 500 | Loss: 6.899005889892578\n",
      "step: 510 | Loss: 6.890286445617676\n",
      "step: 520 | Loss: 6.904943466186523\n",
      "step: 530 | Loss: 6.896718978881836\n",
      "step: 540 | Loss: 6.90205192565918\n",
      "Epoch 1/90, Training Loss: 9.8301, Validation Loss: 6.8995, Validation Accuracy: 0.12%\n",
      "step: 550 | Loss: 6.88750696182251\n",
      "step: 560 | Loss: 6.906826019287109\n",
      "step: 570 | Loss: 6.887200832366943\n",
      "step: 580 | Loss: 6.900623798370361\n",
      "step: 590 | Loss: 6.8704609870910645\n",
      "step: 600 | Loss: 6.9053568840026855\n",
      "step: 610 | Loss: 6.8849101066589355\n",
      "step: 620 | Loss: 6.898086071014404\n",
      "step: 630 | Loss: 6.848428726196289\n",
      "step: 640 | Loss: 6.889801025390625\n",
      "step: 650 | Loss: 6.88417387008667\n",
      "step: 660 | Loss: 6.871999740600586\n",
      "step: 670 | Loss: 6.89528751373291\n",
      "step: 680 | Loss: 6.867776393890381\n",
      "step: 690 | Loss: 6.880688667297363\n",
      "step: 700 | Loss: 6.899583339691162\n",
      "step: 710 | Loss: 6.917706489562988\n",
      "step: 720 | Loss: 6.931995391845703\n",
      "step: 730 | Loss: 6.942929267883301\n",
      "step: 740 | Loss: 6.896009922027588\n",
      "step: 750 | Loss: 6.896666526794434\n",
      "step: 760 | Loss: 6.895637035369873\n",
      "step: 770 | Loss: 6.899474620819092\n",
      "step: 780 | Loss: 6.864437103271484\n",
      "step: 790 | Loss: 6.8800835609436035\n",
      "step: 800 | Loss: 6.885396480560303\n",
      "step: 810 | Loss: 6.917222023010254\n",
      "step: 820 | Loss: 6.855686187744141\n",
      "step: 830 | Loss: 6.907221794128418\n",
      "step: 840 | Loss: 6.83972692489624\n",
      "step: 850 | Loss: 6.8944525718688965\n",
      "step: 860 | Loss: 6.912437915802002\n",
      "step: 870 | Loss: 6.848845481872559\n",
      "step: 880 | Loss: 6.83250617980957\n",
      "step: 890 | Loss: 6.8409743309021\n",
      "step: 900 | Loss: 6.830089569091797\n",
      "step: 910 | Loss: 6.925267696380615\n",
      "step: 920 | Loss: 6.875336170196533\n",
      "step: 930 | Loss: 6.90625524520874\n",
      "step: 940 | Loss: 6.853927135467529\n",
      "step: 950 | Loss: 6.836399078369141\n",
      "step: 960 | Loss: 6.892002105712891\n",
      "step: 970 | Loss: 6.868051052093506\n",
      "step: 980 | Loss: 6.871261119842529\n",
      "step: 990 | Loss: 6.84182596206665\n",
      "step: 1000 | Loss: 6.873416423797607\n",
      "step: 1010 | Loss: 6.877213478088379\n",
      "step: 1020 | Loss: 6.868614673614502\n",
      "step: 1030 | Loss: 6.863589286804199\n",
      "step: 1040 | Loss: 6.902747631072998\n",
      "step: 1050 | Loss: 6.867361068725586\n",
      "step: 1060 | Loss: 6.901760578155518\n",
      "step: 1070 | Loss: 6.793422222137451\n",
      "step: 1080 | Loss: 6.920681476593018\n",
      "step: 1090 | Loss: 6.8758440017700195\n",
      "Epoch 2/90, Training Loss: 6.8781, Validation Loss: 6.8687, Validation Accuracy: 0.20%\n",
      "step: 1100 | Loss: 6.815656661987305\n",
      "step: 1110 | Loss: 6.852495193481445\n",
      "step: 1120 | Loss: 6.882776260375977\n",
      "step: 1130 | Loss: 6.851134777069092\n",
      "step: 1140 | Loss: 6.887136936187744\n",
      "step: 1150 | Loss: 6.8493757247924805\n",
      "step: 1160 | Loss: 6.760707855224609\n",
      "step: 1170 | Loss: 6.817439079284668\n",
      "step: 1180 | Loss: 6.822764873504639\n",
      "step: 1190 | Loss: 6.911231517791748\n",
      "step: 1200 | Loss: 6.818467617034912\n",
      "step: 1210 | Loss: 6.826298236846924\n",
      "step: 1220 | Loss: 6.860892295837402\n",
      "step: 1230 | Loss: 6.813037872314453\n",
      "step: 1240 | Loss: 6.8848443031311035\n",
      "step: 1250 | Loss: 6.856367588043213\n",
      "step: 1260 | Loss: 6.848927974700928\n",
      "step: 1270 | Loss: 6.830533504486084\n",
      "step: 1280 | Loss: 6.927834510803223\n",
      "step: 1290 | Loss: 6.849084854125977\n",
      "step: 1300 | Loss: 6.776252269744873\n",
      "step: 1310 | Loss: 6.815654754638672\n",
      "step: 1320 | Loss: 6.8289594650268555\n",
      "step: 1330 | Loss: 6.827898025512695\n",
      "step: 1340 | Loss: 6.888485908508301\n",
      "step: 1350 | Loss: 6.813065528869629\n",
      "step: 1360 | Loss: 6.919190406799316\n",
      "step: 1370 | Loss: 6.90658712387085\n",
      "step: 1380 | Loss: 6.878664016723633\n",
      "step: 1390 | Loss: 6.908082485198975\n",
      "step: 1400 | Loss: 6.766497611999512\n",
      "step: 1410 | Loss: 6.83305549621582\n",
      "step: 1420 | Loss: 6.779329299926758\n",
      "step: 1430 | Loss: 6.840935707092285\n",
      "step: 1440 | Loss: 6.812845706939697\n",
      "step: 1450 | Loss: 6.831075191497803\n",
      "step: 1460 | Loss: 6.842483043670654\n",
      "step: 1470 | Loss: 6.8111371994018555\n",
      "step: 1480 | Loss: 6.890208721160889\n",
      "step: 1490 | Loss: 6.762914657592773\n",
      "step: 1500 | Loss: 6.824079990386963\n",
      "step: 1510 | Loss: 6.857695579528809\n",
      "step: 1520 | Loss: 6.843494415283203\n",
      "step: 1530 | Loss: 6.810946464538574\n",
      "step: 1540 | Loss: 6.730615615844727\n",
      "step: 1550 | Loss: 6.7955756187438965\n",
      "step: 1560 | Loss: 6.839995861053467\n",
      "step: 1570 | Loss: 6.854796886444092\n",
      "step: 1580 | Loss: 6.753878116607666\n",
      "step: 1590 | Loss: 6.723555088043213\n",
      "step: 1600 | Loss: 6.770337104797363\n",
      "step: 1610 | Loss: 6.802959442138672\n",
      "step: 1620 | Loss: 6.793191909790039\n",
      "step: 1630 | Loss: 6.7352705001831055\n",
      "step: 1640 | Loss: 6.764787197113037\n",
      "Epoch 3/90, Training Loss: 6.8291, Validation Loss: 6.7726, Validation Accuracy: 0.39%\n",
      "step: 1650 | Loss: 6.867292881011963\n",
      "step: 1660 | Loss: 6.811825752258301\n",
      "step: 1670 | Loss: 6.687854766845703\n",
      "step: 1680 | Loss: 6.6208648681640625\n",
      "step: 1690 | Loss: 6.8181071281433105\n",
      "step: 1700 | Loss: 6.6858015060424805\n",
      "step: 1710 | Loss: 6.7342143058776855\n",
      "step: 1720 | Loss: 6.693983554840088\n",
      "step: 1730 | Loss: 6.774594783782959\n",
      "step: 1740 | Loss: 6.803438663482666\n",
      "step: 1750 | Loss: 6.690656661987305\n",
      "step: 1760 | Loss: 6.7796406745910645\n",
      "step: 1770 | Loss: 6.7881951332092285\n",
      "step: 1780 | Loss: 6.805108547210693\n",
      "step: 1790 | Loss: 6.7478156089782715\n",
      "step: 1800 | Loss: 6.725889682769775\n",
      "step: 1810 | Loss: 6.745648384094238\n",
      "step: 1820 | Loss: 6.801730632781982\n",
      "step: 1830 | Loss: 6.771000862121582\n",
      "step: 1840 | Loss: 6.812182426452637\n",
      "step: 1850 | Loss: 6.733889102935791\n",
      "step: 1860 | Loss: 6.743596076965332\n",
      "step: 1870 | Loss: 6.714807510375977\n",
      "step: 1880 | Loss: 6.734029769897461\n",
      "step: 1890 | Loss: 6.64504861831665\n",
      "step: 1900 | Loss: 6.727145195007324\n",
      "step: 1910 | Loss: 6.819220066070557\n",
      "step: 1920 | Loss: 6.793478488922119\n",
      "step: 1930 | Loss: 6.70442008972168\n",
      "step: 1940 | Loss: 6.760254383087158\n",
      "step: 1950 | Loss: 6.621899604797363\n",
      "step: 1960 | Loss: 6.769154071807861\n",
      "step: 1970 | Loss: 6.786324501037598\n",
      "step: 1980 | Loss: 6.680582046508789\n",
      "step: 1990 | Loss: 6.657922744750977\n",
      "step: 2000 | Loss: 6.758012771606445\n",
      "step: 2010 | Loss: 6.6800923347473145\n",
      "step: 2020 | Loss: 6.6781840324401855\n",
      "step: 2030 | Loss: 6.787637233734131\n",
      "step: 2040 | Loss: 6.783251762390137\n",
      "step: 2050 | Loss: 6.818090438842773\n",
      "step: 2060 | Loss: 6.820126056671143\n",
      "step: 2070 | Loss: 6.698619365692139\n",
      "step: 2080 | Loss: 6.687319278717041\n",
      "step: 2090 | Loss: 6.659695148468018\n",
      "step: 2100 | Loss: 6.610732078552246\n",
      "step: 2110 | Loss: 6.633388042449951\n",
      "step: 2120 | Loss: 6.650757312774658\n",
      "step: 2130 | Loss: 6.808320999145508\n",
      "step: 2140 | Loss: 6.6496806144714355\n",
      "step: 2150 | Loss: 6.706074237823486\n",
      "step: 2160 | Loss: 6.7494096755981445\n",
      "step: 2170 | Loss: 6.827586650848389\n",
      "step: 2180 | Loss: 6.683340549468994\n",
      "Epoch 4/90, Training Loss: 6.7253, Validation Loss: 6.6608, Validation Accuracy: 0.61%\n",
      "step: 2190 | Loss: 6.642584323883057\n",
      "step: 2200 | Loss: 6.641919136047363\n",
      "step: 2210 | Loss: 6.661345958709717\n",
      "step: 2220 | Loss: 6.60086727142334\n",
      "step: 2230 | Loss: 6.717545986175537\n",
      "step: 2240 | Loss: 6.582975387573242\n",
      "step: 2250 | Loss: 6.622881889343262\n",
      "step: 2260 | Loss: 6.620088577270508\n",
      "step: 2270 | Loss: 6.592533111572266\n",
      "step: 2280 | Loss: 6.7130937576293945\n",
      "step: 2290 | Loss: 6.561579704284668\n",
      "step: 2300 | Loss: 6.544026851654053\n",
      "step: 2310 | Loss: 6.654595375061035\n",
      "step: 2320 | Loss: 6.56429386138916\n",
      "step: 2330 | Loss: 6.6049113273620605\n",
      "step: 2340 | Loss: 6.6996965408325195\n",
      "step: 2350 | Loss: 6.577452182769775\n",
      "step: 2360 | Loss: 6.444756031036377\n",
      "step: 2370 | Loss: 6.608025550842285\n",
      "step: 2380 | Loss: 6.6665191650390625\n",
      "step: 2390 | Loss: 6.681434154510498\n",
      "step: 2400 | Loss: 6.525136470794678\n",
      "step: 2410 | Loss: 6.65163516998291\n",
      "step: 2420 | Loss: 6.559600353240967\n",
      "step: 2430 | Loss: 6.614457130432129\n",
      "step: 2440 | Loss: 6.601734638214111\n",
      "step: 2450 | Loss: 6.610435485839844\n",
      "step: 2460 | Loss: 6.751043796539307\n",
      "step: 2470 | Loss: 6.464052677154541\n",
      "step: 2480 | Loss: 6.555609226226807\n",
      "step: 2490 | Loss: 6.482010364532471\n",
      "step: 2500 | Loss: 6.610161304473877\n",
      "step: 2510 | Loss: 6.460390090942383\n",
      "step: 2520 | Loss: 6.609411716461182\n",
      "step: 2530 | Loss: 6.43603515625\n",
      "step: 2540 | Loss: 6.631474494934082\n",
      "step: 2550 | Loss: 6.435578346252441\n",
      "step: 2560 | Loss: 6.557122707366943\n",
      "step: 2570 | Loss: 6.543338298797607\n",
      "step: 2580 | Loss: 6.5840888023376465\n",
      "step: 2590 | Loss: 6.463154315948486\n",
      "step: 2600 | Loss: 6.535080909729004\n",
      "step: 2610 | Loss: 6.479550838470459\n",
      "step: 2620 | Loss: 6.531723976135254\n",
      "step: 2630 | Loss: 6.520010948181152\n",
      "step: 2640 | Loss: 6.491998672485352\n",
      "step: 2650 | Loss: 6.502926349639893\n",
      "step: 2660 | Loss: 6.558291435241699\n",
      "step: 2670 | Loss: 6.336092948913574\n",
      "step: 2680 | Loss: 6.510075569152832\n",
      "step: 2690 | Loss: 6.413764953613281\n",
      "step: 2700 | Loss: 6.4100141525268555\n",
      "step: 2710 | Loss: 6.5554962158203125\n",
      "step: 2720 | Loss: 6.352941989898682\n",
      "step: 2730 | Loss: 6.511224269866943\n",
      "Epoch 5/90, Training Loss: 6.5628, Validation Loss: 6.4276, Validation Accuracy: 1.08%\n",
      "step: 2740 | Loss: 6.435137748718262\n",
      "step: 2750 | Loss: 6.491868495941162\n",
      "step: 2760 | Loss: 6.311732769012451\n",
      "step: 2770 | Loss: 6.526931285858154\n",
      "step: 2780 | Loss: 6.3033366203308105\n",
      "step: 2790 | Loss: 6.532667636871338\n",
      "step: 2800 | Loss: 6.427482604980469\n",
      "step: 2810 | Loss: 6.36044454574585\n",
      "step: 2820 | Loss: 6.300887107849121\n",
      "step: 2830 | Loss: 6.3213419914245605\n",
      "step: 2840 | Loss: 6.411150932312012\n",
      "step: 2850 | Loss: 6.400805950164795\n",
      "step: 2860 | Loss: 6.374091148376465\n",
      "step: 2870 | Loss: 6.395289897918701\n",
      "step: 2880 | Loss: 6.430556774139404\n",
      "step: 2890 | Loss: 6.261805534362793\n",
      "step: 2900 | Loss: 6.18613862991333\n",
      "step: 2910 | Loss: 6.308784484863281\n",
      "step: 2920 | Loss: 6.312143802642822\n",
      "step: 2930 | Loss: 6.348688125610352\n",
      "step: 2940 | Loss: 6.32578706741333\n",
      "step: 2950 | Loss: 6.408213138580322\n",
      "step: 2960 | Loss: 6.0938520431518555\n",
      "step: 2970 | Loss: 6.422260761260986\n",
      "step: 2980 | Loss: 6.372465133666992\n",
      "step: 2990 | Loss: 6.25376033782959\n",
      "step: 3000 | Loss: 6.177422046661377\n",
      "step: 3010 | Loss: 6.5134735107421875\n",
      "step: 3020 | Loss: 6.362436294555664\n",
      "step: 3030 | Loss: 6.358899116516113\n",
      "step: 3040 | Loss: 6.36683988571167\n",
      "step: 3050 | Loss: 6.467960357666016\n",
      "step: 3060 | Loss: 6.322530746459961\n",
      "step: 3070 | Loss: 6.375051021575928\n",
      "step: 3080 | Loss: 6.3307952880859375\n",
      "step: 3090 | Loss: 6.291635036468506\n",
      "step: 3100 | Loss: 6.444968223571777\n",
      "step: 3110 | Loss: 6.270686626434326\n",
      "step: 3120 | Loss: 6.153392314910889\n",
      "step: 3130 | Loss: 6.334437370300293\n",
      "step: 3140 | Loss: 6.3217692375183105\n",
      "step: 3150 | Loss: 6.272137641906738\n",
      "step: 3160 | Loss: 6.3024749755859375\n",
      "step: 3170 | Loss: 6.50526762008667\n",
      "step: 3180 | Loss: 6.240787506103516\n",
      "step: 3190 | Loss: 6.069472312927246\n",
      "step: 3200 | Loss: 6.121604919433594\n",
      "step: 3210 | Loss: 6.45085334777832\n",
      "step: 3220 | Loss: 6.157924175262451\n",
      "step: 3230 | Loss: 6.337891101837158\n",
      "step: 3240 | Loss: 6.376029014587402\n",
      "step: 3250 | Loss: 6.270023345947266\n",
      "step: 3260 | Loss: 6.263377666473389\n",
      "step: 3270 | Loss: 6.163242816925049\n",
      "step: 3280 | Loss: 6.035355091094971\n",
      "Epoch 6/90, Training Loss: 6.3279, Validation Loss: 6.1792, Validation Accuracy: 1.79%\n",
      "step: 3290 | Loss: 6.072002410888672\n",
      "step: 3300 | Loss: 6.286137580871582\n",
      "step: 3310 | Loss: 6.228610038757324\n",
      "step: 3320 | Loss: 6.136672496795654\n",
      "step: 3330 | Loss: 6.203329563140869\n",
      "step: 3340 | Loss: 6.001798152923584\n",
      "step: 3350 | Loss: 6.133997440338135\n",
      "step: 3360 | Loss: 6.241608142852783\n",
      "step: 3370 | Loss: 6.134720325469971\n",
      "step: 3380 | Loss: 6.091902256011963\n",
      "step: 3390 | Loss: 6.135233402252197\n",
      "step: 3400 | Loss: 6.171722888946533\n",
      "step: 3410 | Loss: 6.054768085479736\n",
      "step: 3420 | Loss: 6.425579071044922\n",
      "step: 3430 | Loss: 6.083600044250488\n",
      "step: 3440 | Loss: 6.142682075500488\n",
      "step: 3450 | Loss: 6.16985559463501\n",
      "step: 3460 | Loss: 6.014132022857666\n",
      "step: 3470 | Loss: 6.005179405212402\n",
      "step: 3480 | Loss: 6.400216102600098\n",
      "step: 3490 | Loss: 6.118241310119629\n",
      "step: 3500 | Loss: 6.2046685218811035\n",
      "step: 3510 | Loss: 6.236995697021484\n",
      "step: 3520 | Loss: 6.02984094619751\n",
      "step: 3530 | Loss: 6.056278228759766\n",
      "step: 3540 | Loss: 5.834483623504639\n",
      "step: 3550 | Loss: 6.104089736938477\n",
      "step: 3560 | Loss: 6.114497661590576\n",
      "step: 3570 | Loss: 5.9012885093688965\n",
      "step: 3580 | Loss: 6.1053080558776855\n",
      "step: 3590 | Loss: 6.01676082611084\n",
      "step: 3600 | Loss: 5.946115016937256\n",
      "step: 3610 | Loss: 5.980239391326904\n",
      "step: 3620 | Loss: 5.9062886238098145\n",
      "step: 3630 | Loss: 5.838622093200684\n",
      "step: 3640 | Loss: 6.117199897766113\n",
      "step: 3650 | Loss: 6.189382553100586\n",
      "step: 3660 | Loss: 5.86838436126709\n",
      "step: 3670 | Loss: 5.913341999053955\n",
      "step: 3680 | Loss: 6.181288242340088\n",
      "step: 3690 | Loss: 6.078616619110107\n",
      "step: 3700 | Loss: 5.957526683807373\n",
      "step: 3710 | Loss: 6.024415969848633\n",
      "step: 3720 | Loss: 5.9594645500183105\n",
      "step: 3730 | Loss: 5.87631368637085\n",
      "step: 3740 | Loss: 5.811534404754639\n",
      "step: 3750 | Loss: 5.853271484375\n",
      "step: 3760 | Loss: 5.9370551109313965\n",
      "step: 3770 | Loss: 5.874790191650391\n",
      "step: 3780 | Loss: 6.320793151855469\n",
      "step: 3790 | Loss: 5.806715965270996\n",
      "step: 3800 | Loss: 5.817323684692383\n",
      "step: 3810 | Loss: 5.973916053771973\n",
      "step: 3820 | Loss: 5.861446380615234\n",
      "Epoch 7/90, Training Loss: 6.0627, Validation Loss: 5.9174, Validation Accuracy: 2.76%\n",
      "step: 3830 | Loss: 5.870951175689697\n",
      "step: 3840 | Loss: 6.022058486938477\n",
      "step: 3850 | Loss: 5.822536945343018\n",
      "step: 3860 | Loss: 5.96381139755249\n",
      "step: 3870 | Loss: 5.838247776031494\n",
      "step: 3880 | Loss: 5.780930519104004\n",
      "step: 3890 | Loss: 5.838932514190674\n",
      "step: 3900 | Loss: 6.05443000793457\n",
      "step: 3910 | Loss: 5.677860260009766\n",
      "step: 3920 | Loss: 5.618081569671631\n",
      "step: 3930 | Loss: 5.91912841796875\n",
      "step: 3940 | Loss: 5.848577499389648\n",
      "step: 3950 | Loss: 5.774980068206787\n",
      "step: 3960 | Loss: 5.866757392883301\n",
      "step: 3970 | Loss: 5.742058753967285\n",
      "step: 3980 | Loss: 5.629376411437988\n",
      "step: 3990 | Loss: 5.71258020401001\n",
      "step: 4000 | Loss: 5.8471999168396\n",
      "step: 4010 | Loss: 5.8038716316223145\n",
      "step: 4020 | Loss: 5.735628604888916\n",
      "step: 4030 | Loss: 5.531787872314453\n",
      "step: 4040 | Loss: 5.609406471252441\n",
      "step: 4050 | Loss: 5.693883419036865\n",
      "step: 4060 | Loss: 5.661905288696289\n",
      "step: 4070 | Loss: 5.708341598510742\n",
      "step: 4080 | Loss: 5.911012172698975\n",
      "step: 4090 | Loss: 5.635404109954834\n",
      "step: 4100 | Loss: 5.801974773406982\n",
      "step: 4110 | Loss: 5.739299774169922\n",
      "step: 4120 | Loss: 5.847306251525879\n",
      "step: 4130 | Loss: 5.917440414428711\n",
      "step: 4140 | Loss: 5.625810623168945\n",
      "step: 4150 | Loss: 5.7143425941467285\n",
      "step: 4160 | Loss: 5.621654987335205\n",
      "step: 4170 | Loss: 5.627520561218262\n",
      "step: 4180 | Loss: 5.486649990081787\n",
      "step: 4190 | Loss: 5.612743854522705\n",
      "step: 4200 | Loss: 5.7345685958862305\n",
      "step: 4210 | Loss: 5.7438740730285645\n",
      "step: 4220 | Loss: 5.780086994171143\n",
      "step: 4230 | Loss: 5.9231977462768555\n",
      "step: 4240 | Loss: 5.659116744995117\n",
      "step: 4250 | Loss: 5.704154968261719\n",
      "step: 4260 | Loss: 5.775949954986572\n",
      "step: 4270 | Loss: 5.661502838134766\n",
      "step: 4280 | Loss: 5.544613361358643\n",
      "step: 4290 | Loss: 5.699612617492676\n",
      "step: 4300 | Loss: 5.578907489776611\n",
      "step: 4310 | Loss: 5.556179523468018\n",
      "step: 4320 | Loss: 5.781922340393066\n",
      "step: 4330 | Loss: 5.472515106201172\n",
      "step: 4340 | Loss: 5.907060146331787\n",
      "step: 4350 | Loss: 5.660981178283691\n",
      "step: 4360 | Loss: 5.642834186553955\n",
      "step: 4370 | Loss: 5.663000583648682\n",
      "Epoch 8/90, Training Loss: 5.7642, Validation Loss: 5.6239, Validation Accuracy: 4.75%\n",
      "step: 4380 | Loss: 5.170601844787598\n",
      "step: 4390 | Loss: 5.46614933013916\n",
      "step: 4400 | Loss: 5.729562759399414\n",
      "step: 4410 | Loss: 5.4950032234191895\n",
      "step: 4420 | Loss: 5.601650238037109\n",
      "step: 4430 | Loss: 5.24343204498291\n",
      "step: 4440 | Loss: 5.731846809387207\n",
      "step: 4450 | Loss: 5.474235534667969\n",
      "step: 4460 | Loss: 5.4869384765625\n",
      "step: 4470 | Loss: 5.65910530090332\n",
      "step: 4480 | Loss: 5.580406665802002\n",
      "step: 4490 | Loss: 5.447958469390869\n",
      "step: 4500 | Loss: 5.460834980010986\n",
      "step: 4510 | Loss: 5.762554168701172\n",
      "step: 4520 | Loss: 5.679751873016357\n",
      "step: 4530 | Loss: 5.501152515411377\n",
      "step: 4540 | Loss: 5.488013744354248\n",
      "step: 4550 | Loss: 5.423018932342529\n",
      "step: 4560 | Loss: 5.630389213562012\n",
      "step: 4570 | Loss: 5.536602020263672\n",
      "step: 4580 | Loss: 5.259759426116943\n",
      "step: 4590 | Loss: 5.362788200378418\n",
      "step: 4600 | Loss: 5.270308971405029\n",
      "step: 4610 | Loss: 5.490118026733398\n",
      "step: 4620 | Loss: 5.674196243286133\n",
      "step: 4630 | Loss: 5.569409370422363\n",
      "step: 4640 | Loss: 5.614638328552246\n",
      "step: 4650 | Loss: 5.316712856292725\n",
      "step: 4660 | Loss: 5.128573417663574\n",
      "step: 4670 | Loss: 5.49289608001709\n",
      "step: 4680 | Loss: 5.705780506134033\n",
      "step: 4690 | Loss: 5.56529426574707\n",
      "step: 4700 | Loss: 5.487144470214844\n",
      "step: 4710 | Loss: 5.722448825836182\n",
      "step: 4720 | Loss: 5.497445583343506\n",
      "step: 4730 | Loss: 5.392866611480713\n",
      "step: 4740 | Loss: 5.228077411651611\n",
      "step: 4750 | Loss: 5.3879780769348145\n",
      "step: 4760 | Loss: 5.3972015380859375\n",
      "step: 4770 | Loss: 5.280088424682617\n",
      "step: 4780 | Loss: 5.465560436248779\n",
      "step: 4790 | Loss: 5.397587776184082\n",
      "step: 4800 | Loss: 5.608092308044434\n",
      "step: 4810 | Loss: 5.290792942047119\n",
      "step: 4820 | Loss: 5.468757629394531\n",
      "step: 4830 | Loss: 5.542139053344727\n",
      "step: 4840 | Loss: 5.1666951179504395\n",
      "step: 4850 | Loss: 5.352950096130371\n",
      "step: 4860 | Loss: 5.130331516265869\n",
      "step: 4870 | Loss: 5.45680046081543\n",
      "step: 4880 | Loss: 5.458869457244873\n",
      "step: 4890 | Loss: 5.360795974731445\n",
      "step: 4900 | Loss: 5.293381690979004\n",
      "step: 4910 | Loss: 5.2751145362854\n",
      "step: 4920 | Loss: 5.154319763183594\n",
      "Epoch 9/90, Training Loss: 5.4758, Validation Loss: 5.3945, Validation Accuracy: 6.35%\n",
      "step: 4930 | Loss: 5.314135551452637\n",
      "step: 4940 | Loss: 5.389346122741699\n",
      "step: 4950 | Loss: 5.372467517852783\n",
      "step: 4960 | Loss: 5.286073207855225\n",
      "step: 4970 | Loss: 5.123481750488281\n",
      "step: 4980 | Loss: 5.2816948890686035\n",
      "step: 4990 | Loss: 5.2031145095825195\n",
      "step: 5000 | Loss: 5.504524230957031\n",
      "step: 5010 | Loss: 5.095865249633789\n",
      "step: 5020 | Loss: 5.040767669677734\n",
      "step: 5030 | Loss: 5.49265718460083\n",
      "step: 5040 | Loss: 5.177568435668945\n",
      "step: 5050 | Loss: 5.077717304229736\n",
      "step: 5060 | Loss: 5.447750091552734\n",
      "step: 5070 | Loss: 5.146557331085205\n",
      "step: 5080 | Loss: 5.141937255859375\n",
      "step: 5090 | Loss: 5.052717685699463\n",
      "step: 5100 | Loss: 5.3147873878479\n",
      "step: 5110 | Loss: 5.090367317199707\n",
      "step: 5120 | Loss: 5.125215530395508\n",
      "step: 5130 | Loss: 5.257195949554443\n",
      "step: 5140 | Loss: 4.962896823883057\n",
      "step: 5150 | Loss: 5.35896110534668\n",
      "step: 5160 | Loss: 5.438482761383057\n",
      "step: 5170 | Loss: 5.273158550262451\n",
      "step: 5180 | Loss: 5.411953449249268\n",
      "step: 5190 | Loss: 4.96666955947876\n",
      "step: 5200 | Loss: 5.116229057312012\n",
      "step: 5210 | Loss: 5.222563743591309\n",
      "step: 5220 | Loss: 5.2180562019348145\n",
      "step: 5230 | Loss: 5.028771877288818\n",
      "step: 5240 | Loss: 5.193516254425049\n",
      "step: 5250 | Loss: 5.012428283691406\n",
      "step: 5260 | Loss: 5.004003047943115\n",
      "step: 5270 | Loss: 5.2090163230896\n",
      "step: 5280 | Loss: 5.1710944175720215\n",
      "step: 5290 | Loss: 4.965848445892334\n",
      "step: 5300 | Loss: 5.265405178070068\n",
      "step: 5310 | Loss: 5.191140174865723\n",
      "step: 5320 | Loss: 5.346259117126465\n",
      "step: 5330 | Loss: 4.979541778564453\n",
      "step: 5340 | Loss: 5.085807800292969\n",
      "step: 5350 | Loss: 5.1668524742126465\n",
      "step: 5360 | Loss: 5.134108543395996\n",
      "step: 5370 | Loss: 5.057840824127197\n",
      "step: 5380 | Loss: 5.39797830581665\n",
      "step: 5390 | Loss: 5.171721458435059\n",
      "step: 5400 | Loss: 5.037045955657959\n",
      "step: 5410 | Loss: 5.082657814025879\n",
      "step: 5420 | Loss: 5.230962753295898\n",
      "step: 5430 | Loss: 5.035757064819336\n",
      "step: 5440 | Loss: 5.076743125915527\n",
      "step: 5450 | Loss: 5.222053527832031\n",
      "step: 5460 | Loss: 5.471377849578857\n",
      "step: 5470 | Loss: 5.022126197814941\n",
      "Epoch 10/90, Training Loss: 5.2047, Validation Loss: 5.1470, Validation Accuracy: 8.52%\n",
      "step: 5480 | Loss: 4.9490885734558105\n",
      "step: 5490 | Loss: 4.933678150177002\n",
      "step: 5500 | Loss: 5.236220359802246\n",
      "step: 5510 | Loss: 4.727860927581787\n",
      "step: 5520 | Loss: 4.995940208435059\n",
      "step: 5530 | Loss: 4.899659633636475\n",
      "step: 5540 | Loss: 4.887770652770996\n",
      "step: 5550 | Loss: 5.092503547668457\n",
      "step: 5560 | Loss: 5.11163854598999\n",
      "step: 5570 | Loss: 4.845276355743408\n",
      "step: 5580 | Loss: 4.860467910766602\n",
      "step: 5590 | Loss: 4.990548610687256\n",
      "step: 5600 | Loss: 5.001237392425537\n",
      "step: 5610 | Loss: 4.9447808265686035\n",
      "step: 5620 | Loss: 4.8877153396606445\n",
      "step: 5630 | Loss: 4.929645538330078\n",
      "step: 5640 | Loss: 4.946874141693115\n",
      "step: 5650 | Loss: 5.302009582519531\n",
      "step: 5660 | Loss: 5.025519371032715\n",
      "step: 5670 | Loss: 4.972619533538818\n",
      "step: 5680 | Loss: 4.828728199005127\n",
      "step: 5690 | Loss: 4.879174709320068\n",
      "step: 5700 | Loss: 4.745975971221924\n",
      "step: 5710 | Loss: 4.994782447814941\n",
      "step: 5720 | Loss: 5.2779765129089355\n",
      "step: 5730 | Loss: 4.734444618225098\n",
      "step: 5740 | Loss: 4.887452125549316\n",
      "step: 5750 | Loss: 4.953700065612793\n",
      "step: 5760 | Loss: 4.895910739898682\n",
      "step: 5770 | Loss: 4.934494495391846\n",
      "step: 5780 | Loss: 4.646893501281738\n",
      "step: 5790 | Loss: 5.002037048339844\n",
      "step: 5800 | Loss: 4.980684757232666\n",
      "step: 5810 | Loss: 5.09292459487915\n",
      "step: 5820 | Loss: 4.795834064483643\n",
      "step: 5830 | Loss: 4.968369960784912\n",
      "step: 5840 | Loss: 4.975703239440918\n",
      "step: 5850 | Loss: 5.169687747955322\n",
      "step: 5860 | Loss: 5.002993583679199\n",
      "step: 5870 | Loss: 4.739422798156738\n",
      "step: 5880 | Loss: 4.847285747528076\n",
      "step: 5890 | Loss: 4.981399059295654\n",
      "step: 5900 | Loss: 4.829963207244873\n",
      "step: 5910 | Loss: 4.991330146789551\n",
      "step: 5920 | Loss: 5.074520111083984\n",
      "step: 5930 | Loss: 4.920319080352783\n",
      "step: 5940 | Loss: 4.846839427947998\n",
      "step: 5950 | Loss: 4.745022773742676\n",
      "step: 5960 | Loss: 4.887491226196289\n",
      "step: 5970 | Loss: 4.832665920257568\n",
      "step: 5980 | Loss: 4.603270053863525\n",
      "step: 5990 | Loss: 4.634425640106201\n",
      "step: 6000 | Loss: 5.11872673034668\n",
      "step: 6010 | Loss: 5.01718282699585\n",
      "Epoch 11/90, Training Loss: 4.9675, Validation Loss: 4.9534, Validation Accuracy: 10.23%\n",
      "step: 6020 | Loss: 4.8301496505737305\n",
      "step: 6030 | Loss: 4.884462356567383\n",
      "step: 6040 | Loss: 4.746140003204346\n",
      "step: 6050 | Loss: 4.913622856140137\n",
      "step: 6060 | Loss: 4.458325386047363\n",
      "step: 6070 | Loss: 4.816065311431885\n",
      "step: 6080 | Loss: 4.782665252685547\n",
      "step: 6090 | Loss: 4.784151077270508\n",
      "step: 6100 | Loss: 4.541239261627197\n",
      "step: 6110 | Loss: 4.628097057342529\n",
      "step: 6120 | Loss: 4.890040397644043\n",
      "step: 6130 | Loss: 4.711627960205078\n",
      "step: 6140 | Loss: 5.123617649078369\n",
      "step: 6150 | Loss: 4.9489336013793945\n",
      "step: 6160 | Loss: 4.757088661193848\n",
      "step: 6170 | Loss: 4.610103130340576\n",
      "step: 6180 | Loss: 4.869113445281982\n",
      "step: 6190 | Loss: 4.6723833084106445\n",
      "step: 6200 | Loss: 4.96312952041626\n",
      "step: 6210 | Loss: 4.98817777633667\n",
      "step: 6220 | Loss: 4.740422248840332\n",
      "step: 6230 | Loss: 4.716332912445068\n",
      "step: 6240 | Loss: 4.597228050231934\n",
      "step: 6250 | Loss: 4.776655197143555\n",
      "step: 6260 | Loss: 4.705479145050049\n",
      "step: 6270 | Loss: 4.643746376037598\n",
      "step: 6280 | Loss: 4.771190166473389\n",
      "step: 6290 | Loss: 4.921200275421143\n",
      "step: 6300 | Loss: 4.9467973709106445\n",
      "step: 6310 | Loss: 4.562405586242676\n",
      "step: 6320 | Loss: 4.663944721221924\n",
      "step: 6330 | Loss: 4.735243320465088\n",
      "step: 6340 | Loss: 4.555442810058594\n",
      "step: 6350 | Loss: 4.790578842163086\n",
      "step: 6360 | Loss: 4.587821006774902\n",
      "step: 6370 | Loss: 4.940201282501221\n",
      "step: 6380 | Loss: 4.750672817230225\n",
      "step: 6390 | Loss: 4.587470531463623\n",
      "step: 6400 | Loss: 4.578969955444336\n",
      "step: 6410 | Loss: 5.018557548522949\n",
      "step: 6420 | Loss: 4.895429611206055\n",
      "step: 6430 | Loss: 4.600032806396484\n",
      "step: 6440 | Loss: 4.686855792999268\n",
      "step: 6450 | Loss: 4.58399772644043\n",
      "step: 6460 | Loss: 4.667877197265625\n",
      "step: 6470 | Loss: 4.752782344818115\n",
      "step: 6480 | Loss: 4.738809585571289\n",
      "step: 6490 | Loss: 4.352398872375488\n",
      "step: 6500 | Loss: 4.608354568481445\n",
      "step: 6510 | Loss: 4.799034118652344\n",
      "step: 6520 | Loss: 4.682661056518555\n",
      "step: 6530 | Loss: 4.6977691650390625\n",
      "step: 6540 | Loss: 4.646121978759766\n",
      "step: 6550 | Loss: 4.73363733291626\n",
      "step: 6560 | Loss: 5.006316184997559\n",
      "Epoch 12/90, Training Loss: 4.7432, Validation Loss: 4.7480, Validation Accuracy: 12.15%\n",
      "step: 6570 | Loss: 4.537765026092529\n",
      "step: 6580 | Loss: 4.561141490936279\n",
      "step: 6590 | Loss: 4.6215386390686035\n",
      "step: 6600 | Loss: 4.369097709655762\n",
      "step: 6610 | Loss: 4.614821910858154\n",
      "step: 6620 | Loss: 4.6704816818237305\n",
      "step: 6630 | Loss: 4.7032647132873535\n",
      "step: 6640 | Loss: 4.625095367431641\n",
      "step: 6650 | Loss: 4.603268623352051\n",
      "step: 6660 | Loss: 4.758629322052002\n",
      "step: 6670 | Loss: 4.278672218322754\n",
      "step: 6680 | Loss: 4.628961086273193\n",
      "step: 6690 | Loss: 4.237664699554443\n",
      "step: 6700 | Loss: 4.678986072540283\n",
      "step: 6710 | Loss: 4.487758159637451\n",
      "step: 6720 | Loss: 4.519538879394531\n",
      "step: 6730 | Loss: 4.7521162033081055\n",
      "step: 6740 | Loss: 4.513893127441406\n",
      "step: 6750 | Loss: 4.385430335998535\n",
      "step: 6760 | Loss: 4.582682132720947\n",
      "step: 6770 | Loss: 4.813037395477295\n",
      "step: 6780 | Loss: 4.598460674285889\n",
      "step: 6790 | Loss: 4.640564441680908\n",
      "step: 6800 | Loss: 4.509787082672119\n",
      "step: 6810 | Loss: 4.587468147277832\n",
      "step: 6820 | Loss: 4.503684043884277\n",
      "step: 6830 | Loss: 4.548085689544678\n",
      "step: 6840 | Loss: 4.9229631423950195\n",
      "step: 6850 | Loss: 4.403117656707764\n",
      "step: 6860 | Loss: 4.366267204284668\n",
      "step: 6870 | Loss: 4.348263263702393\n",
      "step: 6880 | Loss: 4.652438163757324\n",
      "step: 6890 | Loss: 4.498932361602783\n",
      "step: 6900 | Loss: 4.546915054321289\n",
      "step: 6910 | Loss: 4.7713093757629395\n",
      "step: 6920 | Loss: 4.506319522857666\n",
      "step: 6930 | Loss: 4.657482624053955\n",
      "step: 6940 | Loss: 4.664353847503662\n",
      "step: 6950 | Loss: 4.051391124725342\n",
      "step: 6960 | Loss: 4.455384731292725\n",
      "step: 6970 | Loss: 4.54385232925415\n",
      "step: 6980 | Loss: 4.46467924118042\n",
      "step: 6990 | Loss: 4.258544921875\n",
      "step: 7000 | Loss: 4.537395477294922\n",
      "step: 7010 | Loss: 4.126926422119141\n",
      "step: 7020 | Loss: 4.59011173248291\n",
      "step: 7030 | Loss: 4.6115570068359375\n",
      "step: 7040 | Loss: 4.4785614013671875\n",
      "step: 7050 | Loss: 4.417052268981934\n",
      "step: 7060 | Loss: 4.5538010597229\n",
      "step: 7070 | Loss: 4.272880554199219\n",
      "step: 7080 | Loss: 4.628852844238281\n",
      "step: 7090 | Loss: 4.353914260864258\n",
      "step: 7100 | Loss: 4.582353115081787\n",
      "step: 7110 | Loss: 4.589846134185791\n",
      "Epoch 13/90, Training Loss: 4.5342, Validation Loss: 4.5749, Validation Accuracy: 14.12%\n",
      "step: 7120 | Loss: 4.289367198944092\n",
      "step: 7130 | Loss: 4.376894474029541\n",
      "step: 7140 | Loss: 3.9853053092956543\n",
      "step: 7150 | Loss: 4.139516830444336\n",
      "step: 7160 | Loss: 4.594890594482422\n",
      "step: 7170 | Loss: 4.377457141876221\n",
      "step: 7180 | Loss: 4.505730152130127\n",
      "step: 7190 | Loss: 4.283728122711182\n",
      "step: 7200 | Loss: 4.367593765258789\n",
      "step: 7210 | Loss: 4.232268333435059\n",
      "step: 7220 | Loss: 4.4411821365356445\n",
      "step: 7230 | Loss: 4.377749919891357\n",
      "step: 7240 | Loss: 4.080255508422852\n",
      "step: 7250 | Loss: 4.4311041831970215\n",
      "step: 7260 | Loss: 4.485572814941406\n",
      "step: 7270 | Loss: 4.159958362579346\n",
      "step: 7280 | Loss: 4.522885799407959\n",
      "step: 7290 | Loss: 4.233339309692383\n",
      "step: 7300 | Loss: 4.488254070281982\n",
      "step: 7310 | Loss: 4.516303062438965\n",
      "step: 7320 | Loss: 4.309573173522949\n",
      "step: 7330 | Loss: 4.349037170410156\n",
      "step: 7340 | Loss: 4.287759780883789\n",
      "step: 7350 | Loss: 4.270953178405762\n",
      "step: 7360 | Loss: 4.270172595977783\n",
      "step: 7370 | Loss: 4.317313194274902\n",
      "step: 7380 | Loss: 4.592780590057373\n",
      "step: 7390 | Loss: 4.172679424285889\n",
      "step: 7400 | Loss: 4.530709743499756\n",
      "step: 7410 | Loss: 4.16258430480957\n",
      "step: 7420 | Loss: 4.473235130310059\n",
      "step: 7430 | Loss: 4.251616477966309\n",
      "step: 7440 | Loss: 4.202822208404541\n",
      "step: 7450 | Loss: 4.455598831176758\n",
      "step: 7460 | Loss: 4.3392109870910645\n",
      "step: 7470 | Loss: 4.337954521179199\n",
      "step: 7480 | Loss: 4.022380352020264\n",
      "step: 7490 | Loss: 4.267510414123535\n",
      "step: 7500 | Loss: 4.357592582702637\n",
      "step: 7510 | Loss: 4.33225154876709\n",
      "step: 7520 | Loss: 4.428408145904541\n",
      "step: 7530 | Loss: 4.216222286224365\n",
      "step: 7540 | Loss: 4.716995716094971\n",
      "step: 7550 | Loss: 4.624150276184082\n",
      "step: 7560 | Loss: 4.6978020668029785\n",
      "step: 7570 | Loss: 4.364485263824463\n",
      "step: 7580 | Loss: 4.294358730316162\n",
      "step: 7590 | Loss: 4.301913261413574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \n\u001b[1;32m     86\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     88\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# refreshing gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/torchvision/datasets/folder.py:248\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    247\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/PIL/Image.py:922\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    876\u001b[0m ):\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/PIL/ImageFile.py:271\u001b[0m, in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     self.fp.close()\n\u001b[1;32m    268\u001b[0m self.fp = None\n\u001b[1;32m    270\u001b[0m if not self.map and not LOAD_TRUNCATED_IMAGES and err_code < 0:\n\u001b[0;32m--> 271\u001b[0m     # still raised if decoder fails to return anything\n\u001b[1;32m    272\u001b[0m     raise_oserror(err_code)\n\u001b[1;32m    274\u001b[0m return Image.Image.load(self)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/paper implementation/ImageNet/.venv/lib/python3.9/site-packages/PIL/JpegImagePlugin.py:417\u001b[0m, in \u001b[0;36mload_read\u001b[0;34m(self, read_bytes)\u001b[0m\n\u001b[1;32m    414\u001b[0m if len(self.tile) != 1:\n\u001b[1;32m    415\u001b[0m     return\n\u001b[0;32m--> 417\u001b[0m # Protect from second call\n\u001b[1;32m    418\u001b[0m if self.decoderconfig:\n\u001b[1;32m    419\u001b[0m     return\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "GPUS = [0]\n",
    "EPOCHS = 90\n",
    "NO_CLASSES = 1000\n",
    "TRAIN_DIR = 'imagenet-mini/train'\n",
    "VAL_DIR = 'imagenet-mini/val'\n",
    "IMG_DIM = 227\n",
    "BATCH_SIZE = 128\n",
    "L_RATE = 0.005\n",
    "W_DECAY = 0.0005\n",
    "MOMENTUM = 0.9\n",
    "CHECKPOINT_DIR = 'checkpoints/'\n",
    "\n",
    "data_dir = \"imagenet1k\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "seed = torch.initial_seed()\n",
    "# create model\n",
    "model = AlexNet(classes=NO_CLASSES).to(device)\n",
    "\n",
    "# train with multi GPU\n",
    "model = torch.nn.parallel.DataParallel(model, device_ids=GPUS)\n",
    "\n",
    "# image augmentation and tranformation\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(IMG_DIM),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# parepare the dataset\n",
    "imagenet_data = datasets.ImageFolder(root=data_dir, transform=data_transform)\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(imagenet_data))\n",
    "val_size = int(0.15 * len(imagenet_data))\n",
    "test_size = len(imagenet_data) - train_size - val_size\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_set, val_set, test_set = random_split(imagenet_data, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # num_workers=8\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # num_workers=8\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # num_workers=8\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "# optim = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=L_RATE,\n",
    "#     momentum=MOMENTUM,\n",
    "#     weight_decay=W_DECAY\n",
    "# )\n",
    "\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# decay the learning rate\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=30, gamma=0.1)\n",
    "\n",
    "total_steps =1\n",
    "# training\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for step, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # refreshing gradients\n",
    "        optim.zero_grad()\n",
    "        # forward_pass\n",
    "        pred = model(X)\n",
    "        # taking loss\n",
    "        loss:Tensor = criterion(pred, y).to(device)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # taking step\n",
    "        optim.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        if total_steps % 10 == 0:\n",
    "            print(f'step: {total_steps} | Loss: {loss}')\n",
    "        total_steps += 1\n",
    "\n",
    "     \n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, \"\n",
    "          f\"Training Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "          f\"Validation Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Validation Accuracy: {(correct/total) * 100:.2f}%\")   \n",
    "    \n",
    "    # saving checkpoints\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'model_checkpoint{epoch+1}.pkl')\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'total_steps': total_steps,\n",
    "        'optimizer': optim.load_state_dict,\n",
    "        'model': model.state_dict(),\n",
    "        'seed': seed\n",
    "    }\n",
    "    torch.save(state, checkpoint_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
